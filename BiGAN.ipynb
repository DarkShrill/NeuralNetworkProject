{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiGAN__TEST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y-BEy7WW1sg",
        "outputId": "b37b6179-0f68-4911-f599-b4c229f07ed9"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "from torchvision import datasets\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch import optim\r\n",
        "from torch.autograd import Variable\r\n",
        "import torchvision.utils as vutils\r\n",
        "import torchvision as torchvision\r\n",
        "!pip install barbar\r\n",
        "from barbar import Bar\r\n",
        "# !pip install cifar\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "print(torch.__version__)\r\n",
        "\r\n",
        "# drive.mount('/content/drive')\r\n",
        "\r\n",
        "DATASET_DIR = '/content/drive/My Drive/data/cifar/'\r\n",
        "# DATASET_DIR = '/DATASET/SVHN/'\r\n",
        "# DATASET_DIR = '/DATASET/CELEB_A/'\r\n",
        "IMAGE_DIR = '/content/drive/My Drive/data/images/'\r\n",
        "\r\n",
        "DATASET = \"NULL\"\r\n",
        "\r\n",
        "def get_cifar10(args, data_dir=DATASET_DIR):\r\n",
        "    \"\"\"Returning cifar dataloder.\"\"\"\r\n",
        "    transform = transforms.Compose([transforms.Resize(32), #3x32x32 images.\r\n",
        "                                    transforms.ToTensor()])\r\n",
        "    train = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\r\n",
        "    test = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\r\n",
        "    train_dataloader = DataLoader(train, batch_size=args.batch_size, shuffle=True)\r\n",
        "    test_dataloader = DataLoader(test, batch_size=args.batch_size, shuffle=True)\r\n",
        "    DATASET = \"cifar10\"\r\n",
        "    return train_dataloader,test_dataloader\r\n",
        "\r\n",
        "def get_SVHN(args, data_dir=DATASET_DIR):\r\n",
        "    \"\"\"Returning cifar dataloder.\"\"\"\r\n",
        "    transform = transforms.Compose([transforms.Resize(32), #3x32x32 images.\r\n",
        "                                    transforms.ToTensor()])\r\n",
        "    train = datasets.SVHN(root=data_dir, split='train', download=True, transform=transform)\r\n",
        "    test = datasets.SVHN(root=data_dir, split='test', download=True, transform=transform)\r\n",
        "    train_dataloader = DataLoader(train, batch_size=args.batch_size, shuffle=True)\r\n",
        "    test_dataloader = DataLoader(test, batch_size=args.batch_size, shuffle=True)\r\n",
        "    DATASET = \"SVHN\"\r\n",
        "    return train_dataloader,test_dataloader\r\n",
        "\r\n",
        "def get_CELEB_A(args, data_dir=DATASET_DIR):\r\n",
        "    \"\"\"Returning cifar dataloder.\"\"\"\r\n",
        "    transform = transforms.Compose([transforms.Resize(32), #3x32x32 images.\r\n",
        "                                    transforms.ToTensor()])\r\n",
        "    train = datasets.CelebA(root=data_dir, split='train', download=True, transform=transform)\r\n",
        "    test = datasets.CelebA(root=data_dir, split='test', download=True, transform=transform)\r\n",
        "    train_dataloader = DataLoader(train, batch_size=args.batch_size, shuffle=True)\r\n",
        "    test_dataloader = DataLoader(test, batch_size=args.batch_size, shuffle=True)\r\n",
        "    return train_dataloader,test_dataloader\r\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: barbar in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaP3xdv-YLlQ"
      },
      "source": [
        "def weights_init_normal(m):\r\n",
        "    classname = m.__class__.__name__\r\n",
        "    if classname.find(\"Conv\") != -1 and classname != 'Conv':\r\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 1e-3)\r\n",
        "        if m.bias is not None:\r\n",
        "            m.bias.data.fill_(0)\r\n",
        "    elif classname.find(\"Linear\") != -1:\r\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 1e-3)\r\n",
        "        if m.bias is not None:\r\n",
        "            m.bias.data.fill_(0)\r\n",
        "    elif classname.find('BatchNorm') != -1:\r\n",
        "        m.weight.data.normal_(1.0, 0.01)\r\n",
        "        if m.bias is not None:\r\n",
        "            m.bias.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1XxRaD9YRZw"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self, z_dim=32, wasserstein=False):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "        self.wass = wasserstein\r\n",
        "\r\n",
        "        #Â Inference over x\r\n",
        "        self.conv1x = nn.Conv2d(3, 32, 5, stride=1, bias=False)\r\n",
        "        self.conv2x = nn.Conv2d(32, 64, 4, stride=2, bias=False)\r\n",
        "        self.bn2x = nn.BatchNorm2d(64)\r\n",
        "        self.conv3x = nn.Conv2d(64, 128, 4, stride=1, bias=False)\r\n",
        "        self.bn3x = nn.BatchNorm2d(128)\r\n",
        "        self.conv4x = nn.Conv2d(128, 256, 4, stride=2, bias=False)\r\n",
        "        self.bn4x = nn.BatchNorm2d(256)\r\n",
        "        self.conv5x = nn.Conv2d(256, 512, 4, stride=1, bias=False)\r\n",
        "        self.bn5x = nn.BatchNorm2d(512)\r\n",
        "\r\n",
        "        # Inference over z\r\n",
        "        self.conv1z = nn.Conv2d(z_dim, 512, 1, stride=1, bias=False)\r\n",
        "        self.conv2z = nn.Conv2d(512, 512, 1, stride=1, bias=False)\r\n",
        "\r\n",
        "        # Joint inference\r\n",
        "        self.conv1xz = nn.Conv2d(1024, 1024, 1, stride=1, bias=False)\r\n",
        "        self.conv2xz = nn.Conv2d(1024, 1024, 1, stride=1, bias=False)\r\n",
        "        self.conv3xz = nn.Conv2d(1024, 1, 1, stride=1, bias=False)\r\n",
        "\r\n",
        "    def inf_x(self, x):\r\n",
        "        x = F.dropout2d(F.leaky_relu(self.conv1x(x), negative_slope=0.1), 0.2)\r\n",
        "        x = F.dropout2d(F.leaky_relu(self.bn2x(self.conv2x(x)), negative_slope=0.1), 0.2)\r\n",
        "        x = F.dropout2d(F.leaky_relu(self.bn3x(self.conv3x(x)), negative_slope=0.1), 0.2)\r\n",
        "        x = F.dropout2d(F.leaky_relu(self.bn4x(self.conv4x(x)), negative_slope=0.1), 0.2)\r\n",
        "        x = F.dropout2d(F.leaky_relu(self.bn5x(self.conv5x(x)), negative_slope=0.1), 0.2)\r\n",
        "        return x\r\n",
        "\r\n",
        "    def inf_z(self, z):\r\n",
        "        z = F.dropout2d(F.leaky_relu(self.conv1z(z), negative_slope=0.1), 0.2)\r\n",
        "        z = F.dropout2d(F.leaky_relu(self.conv2z(z), negative_slope=0.1), 0.2)\r\n",
        "        return z\r\n",
        "\r\n",
        "    def inf_xz(self, xz):\r\n",
        "        xz = F.dropout(F.leaky_relu(self.conv1xz(xz), negative_slope=0.1), 0.2)\r\n",
        "        xz = F.dropout(F.leaky_relu(self.conv2xz(xz), negative_slope=0.1), 0.2)\r\n",
        "        return self.conv3xz(xz)\r\n",
        "\r\n",
        "    def forward(self, x, z):\r\n",
        "        x = self.inf_x(x)\r\n",
        "        z = self.inf_z(z)\r\n",
        "        xz = torch.cat((x,z), dim=1)\r\n",
        "        out = self.inf_xz(xz)\r\n",
        "        if self.wass:\r\n",
        "            return out\r\n",
        "        else:\r\n",
        "            return torch.sigmoid(out)\r\n",
        "\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "    def __init__(self, z_dim=32):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "        self.z_dim = z_dim\r\n",
        "\r\n",
        "        self.output_bias = nn.Parameter(torch.zeros(3, 32, 32), requires_grad=True)\r\n",
        "        self.deconv1 = nn.ConvTranspose2d(z_dim, 256, 4, stride=1, bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(256)\r\n",
        "        self.deconv2 = nn.ConvTranspose2d(256, 128, 4, stride=2, bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(128)\r\n",
        "        self.deconv3 = nn.ConvTranspose2d(128, 64, 4, stride=1, bias=False)\r\n",
        "        self.bn3 = nn.BatchNorm2d(64)\r\n",
        "        self.deconv4 = nn.ConvTranspose2d(64, 32, 4, stride=2, bias=False)\r\n",
        "        self.bn4 = nn.BatchNorm2d(32)\r\n",
        "        self.deconv5 = nn.ConvTranspose2d(32, 32, 5, stride=1, bias=False)\r\n",
        "        self.bn5 = nn.BatchNorm2d(32)\r\n",
        "        self.deconv6 = nn.Conv2d(32, 3, 1, stride=1, bias=True)\r\n",
        "\r\n",
        "    def forward(self, z):\r\n",
        "        z = F.leaky_relu(self.bn1(self.deconv1(z)), negative_slope=0.1)\r\n",
        "        z = F.leaky_relu(self.bn2(self.deconv2(z)), negative_slope=0.1)\r\n",
        "        z = F.leaky_relu(self.bn3(self.deconv3(z)), negative_slope=0.1)\r\n",
        "        z = F.leaky_relu(self.bn4(self.deconv4(z)), negative_slope=0.1)\r\n",
        "        z = F.leaky_relu(self.bn5(self.deconv5(z)), negative_slope=0.1)\r\n",
        "        return torch.sigmoid(self.deconv6(z) + self.output_bias)\r\n",
        "\r\n",
        "\r\n",
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, z_dim=32):\r\n",
        "        super(Encoder, self).__init__()\r\n",
        "        self.z_dim = z_dim\r\n",
        "        self.conv1 = nn.Conv2d(3, 32, 5, stride=1, bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(32)\r\n",
        "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2, bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(64)\r\n",
        "        self.conv3 = nn.Conv2d(64, 128, 4, stride=1, bias=False)\r\n",
        "        self.bn3 = nn.BatchNorm2d(128)\r\n",
        "        self.conv4 = nn.Conv2d(128, 256, 4, stride=2, bias=False)\r\n",
        "        self.bn4 = nn.BatchNorm2d(256)\r\n",
        "        self.conv5 = nn.Conv2d(256, 512, 4, stride=1, bias=False)\r\n",
        "        self.bn5 = nn.BatchNorm2d(512)\r\n",
        "        self.conv6 = nn.Conv2d(512, 512, 1, stride=1, bias=False)\r\n",
        "        self.bn6 = nn.BatchNorm2d(512)\r\n",
        "        self.bn7 = nn.Conv2d(512, z_dim*2, 1, stride=1, bias=True)\r\n",
        "\r\n",
        "    def reparameterize(self, z):\r\n",
        "        z = z.view(z.size(0), -1)\r\n",
        "        mu, log_sigma = z[:, :self.z_dim], z[:, self.z_dim:]\r\n",
        "        std = torch.exp(log_sigma)\r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        return mu + eps * std\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.leaky_relu(self.bn1(self.conv1(x)), negative_slope=0.1)\r\n",
        "        x = F.leaky_relu(self.bn2(self.conv2(x)), negative_slope=0.1)\r\n",
        "        x = F.leaky_relu(self.bn3(self.conv3(x)), negative_slope=0.1)\r\n",
        "        x = F.leaky_relu(self.bn4(self.conv4(x)), negative_slope=0.1)\r\n",
        "        x = F.leaky_relu(self.bn5(self.conv5(x)), negative_slope=0.1)\r\n",
        "        x = F.leaky_relu(self.bn6(self.conv6(x)), negative_slope=0.1)\r\n",
        "        z = self.reparameterize(self.conv6(x))\r\n",
        "        return z.view(x.size(0), self.z_dim, 1, 1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_u5CsZCYUjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164d2e37-0ae8-4cd4-8bbc-f0008ecea29f"
      },
      "source": [
        "!pip install tqdm\r\n",
        "from tqdm import tqdm\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import os\r\n",
        "\r\n",
        "def D_loss(DG, DE, eps=1e-6):\r\n",
        "    loss = torch.log(DE + eps) + torch.log(1 - DG + eps)\r\n",
        "    return -torch.mean(loss)\r\n",
        "\r\n",
        "def EG_loss(DG, DE, eps=1e-6):\r\n",
        "  loss = torch.log(DG + eps) + torch.log(1 - DE + eps)\r\n",
        "  return -torch.mean(loss)\r\n",
        "\r\n",
        "if not os.path.exists(\"/prj_gen_images\"):\r\n",
        "    os.makedirs(\"/prj_gen_images\")\r\n",
        "\r\n",
        "class TrainerBiGAN:\r\n",
        "    def __init__(self, args, data, device):\r\n",
        "        self.args = args\r\n",
        "        self.train_loader = data\r\n",
        "        self.device = device\r\n",
        "\r\n",
        "\r\n",
        "    def getModel(self):\r\n",
        "      return self.G,self.D,self.E \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def train(self):\r\n",
        "        \"\"\"Training the BiGAN\"\"\"\r\n",
        "        self.G = Generator(self.args.latent_dim).to(self.device)\r\n",
        "        self.E = Encoder(self.args.latent_dim).to(self.device)\r\n",
        "        self.D = Discriminator(self.args.latent_dim, self.args.wasserstein).to(self.device)\r\n",
        "\r\n",
        "        self.G.apply(weights_init_normal)\r\n",
        "        self.E.apply(weights_init_normal)\r\n",
        "        self.D.apply(weights_init_normal)\r\n",
        "\r\n",
        "        if self.args.wasserstein:\r\n",
        "            optimizer_ge = optim.RMSprop(list(self.G.parameters()) +\r\n",
        "                                         list(self.E.parameters()), lr=self.args.lr_rmsprop)\r\n",
        "            optimizer_d = optim.RMSprop(self.D.parameters(), lr=self.args.lr_rmsprop)\r\n",
        "        else:\r\n",
        "            optimizer_ge = optim.Adam(list(self.G.parameters()) +\r\n",
        "                                      list(self.E.parameters()), lr=self.args.lr_adam)\r\n",
        "            optimizer_d = optim.Adam(self.D.parameters(), lr=self.args.lr_adam)\r\n",
        "\r\n",
        "        fixed_z = Variable(torch.randn((16, self.args.latent_dim, 1, 1)),\r\n",
        "                           requires_grad=False).to(self.device)\r\n",
        "        # criterion = nn.BCELoss()\r\n",
        "        for epoch in range(self.args.num_epochs+1):\r\n",
        "            ge_loss_accuracy = 0\r\n",
        "            d_loss_accuracy = 0\r\n",
        "            for i,(x,label)  in enumerate(tqdm(self.train_loader)):\r\n",
        "\r\n",
        "                ################################################################################################\r\n",
        "                #######################                                         ################################\r\n",
        "                #######################         DISCRIMINATOR TRAINING          ################################\r\n",
        "                #######################                                         ################################\r\n",
        "                ################################################################################################\r\n",
        "\r\n",
        "                # Cleaning gradient of D.\r\n",
        "                optimizer_d.zero_grad()\r\n",
        "\r\n",
        "                # Generator:\r\n",
        "                z_fake = Variable(torch.randn((x.size(0), self.args.latent_dim, 1, 1)).to(self.device),\r\n",
        "                                  requires_grad=False)\r\n",
        "                # compute G(z)\r\n",
        "                x_fake = self.G(z_fake.to(self.device))\r\n",
        "\r\n",
        "                # Encoder:\r\n",
        "                x_true = x.float().to(self.device)\r\n",
        "                # compute E(x)\r\n",
        "                z_true = self.E(x_true)\r\n",
        "\r\n",
        "                # Discriminator\r\n",
        "                # compute D(x, E(x))\r\n",
        "                out_true = self.D(x_true , z_true)#.squeeze(1).squeeze(1)\r\n",
        "                # compute D(G(z),z)\r\n",
        "                out_fake = self.D(x_fake , z_fake)#.squeeze(1).squeeze(1)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "                # compute losses\r\n",
        "                loss_d = D_loss(out_fake,out_true)\r\n",
        "                d_loss_accuracy += loss_d.item()\r\n",
        "                # loss_d = criterion(out_true, y_true) + criterion(out_fake, y_fake)\r\n",
        "\r\n",
        "                # Computing gradients and backpropagate in order to train the discriminator.\r\n",
        "                loss_d.backward()\r\n",
        "                optimizer_d.step()\r\n",
        "\r\n",
        "\r\n",
        "                ################################################################################################\r\n",
        "                #######################                                         ################################\r\n",
        "                #######################         GEN & ENC TRAINING              ################################\r\n",
        "                #######################                                         ################################\r\n",
        "                ################################################################################################\r\n",
        "\r\n",
        "\r\n",
        "                # Cleaning gradient.\r\n",
        "                optimizer_ge.zero_grad()\r\n",
        "\r\n",
        "                # Generator:\r\n",
        "                z_fake = Variable(torch.randn((x.size(0), self.args.latent_dim, 1, 1)).to(self.device),\r\n",
        "                                  requires_grad=False)\r\n",
        "                # compute G(z)\r\n",
        "                x_fake = self.G(z_fake)\r\n",
        "\r\n",
        "                # Encoder:\r\n",
        "                x_true = x.float().to(self.device)\r\n",
        "                # compute E(x)\r\n",
        "                z_true = self.E(x_true)\r\n",
        "\r\n",
        "                # Discriminator\r\n",
        "                # compute D(x, E(x))\r\n",
        "                out_true = self.D(x_true , z_true)#.squeeze(1).squeeze(1)\r\n",
        "                # compute D(G(z),z)\r\n",
        "                out_fake = self.D(x_fake , z_fake)#.squeeze(1).squeeze(1)\r\n",
        "\r\n",
        "                \r\n",
        "                \r\n",
        "                # compute losses\r\n",
        "                loss_ge = EG_loss(out_fake,out_true)\r\n",
        "                ge_loss_accuracy += loss_ge.item()\r\n",
        "\r\n",
        "                # Computing gradients and backpropagate in order to train the generator and encoder.\r\n",
        "                loss_ge.backward()\r\n",
        "                optimizer_ge.step()\r\n",
        "               \r\n",
        "  \r\n",
        "            if epoch % 1 == 0:\r\n",
        "                with torch.no_grad():\r\n",
        "                  z_fake = Variable(torch.randn((x.size(0), self.args.latent_dim, 1, 1)).to(self.device),\r\n",
        "                                    requires_grad=False)\r\n",
        "                  g_result = self.G(z_fake)\r\n",
        "                  ge_result = self.G(self.E(x.float().to(self.device)))\r\n",
        "\r\n",
        "                  vutils.save_image(g_result[:16].data, '/prj_gen_images/{}_G_fake.png'.format(epoch))\r\n",
        "                  vutils.save_image(x[:16].cpu().data, '/prj_gen_images/{}_X_fake.png'.format(epoch))\r\n",
        "                  vutils.save_image(ge_result[:16].data, '/prj_gen_images/{}_G(E(x))_fake.png'.format(epoch))\r\n",
        "\r\n",
        "                  g_img = mpimg.imread('/prj_gen_images/{}_G_fake.png'.format(epoch))\r\n",
        "                  ge_img = mpimg.imread('/prj_gen_images/{}_G(E(x))_fake.png'.format(epoch))\r\n",
        "                  x_img = mpimg.imread('/prj_gen_images/{}_X_fake.png'.format(epoch))\r\n",
        "\r\n",
        "\r\n",
        "                  fig, ax = plt.subplots(3, 1, figsize=(15, 5))\r\n",
        "                  fig.subplots_adjust(wspace=0.05, hspace=0.2)\r\n",
        "                  plt.rcParams.update({'font.size': 20})\r\n",
        "                  fig.suptitle('Epoch {}'.format(epoch))\r\n",
        "                  fig.text(0.04, 0.75, 'G(z)', ha='left')\r\n",
        "                  fig.text(0.04, 0.5, 'x', ha='left')\r\n",
        "                  fig.text(0.04, 0.25, 'G(E(x))', ha='left')\r\n",
        "\r\n",
        "                  ax[0].imshow(g_img, cmap='gray')\r\n",
        "                  ax[0].axis('off')\r\n",
        "                  ax[1].imshow(x_img, cmap='gray')\r\n",
        "                  ax[1].axis('off')\r\n",
        "                  ax[2].imshow(ge_img, cmap='gray')\r\n",
        "                  ax[2].axis('off')\r\n",
        "                  plt.show()\r\n",
        "\r\n",
        "\r\n",
        "            print(\"Training... Epoch: {}, Discrimiantor Loss: {:.3f}, Generator Loss: {:.3f}\".format(\r\n",
        "                epoch, d_loss_accuracy/i, ge_loss_accuracy/i)\r\n",
        "            )\r\n",
        "             \r\n",
        "\r\n",
        "        \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1V2NLzYYin4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a4f369c-136e-4629-f70d-e3986b13862d"
      },
      "source": [
        "import argparse \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=200,\r\n",
        "                        help=\"number of epochs\")\r\n",
        "    parser.add_argument('--lr_adam', type=float, default=1e-4,\r\n",
        "                        help='learning rate')\r\n",
        "    parser.add_argument('--lr_rmsprop', type=float, default=1e-4,\r\n",
        "                        help='learning rate RMSprop if WGAN is True.')\r\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128,\r\n",
        "                        help=\"Batch size\")\r\n",
        "    parser.add_argument('--latent_dim', type=int, default=256,\r\n",
        "                        help='Dimension of the latent variable z')\r\n",
        "    parser.add_argument('--wasserstein', type=bool, default=False,\r\n",
        "                        help='If WGAN.')\r\n",
        "    parser.add_argument('--clamp', type=float, default=1e-2,\r\n",
        "                        help='Clipping gradients for WGAN.')\r\n",
        "\r\n",
        "    #parsing arguments.\r\n",
        "    args = parser.parse_args(args=[]) \r\n",
        "\r\n",
        "    #check if cuda is available.\r\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "    train,test = get_cifar10(args)\r\n",
        "    # train,test = get_SVHN(args)\r\n",
        "    # train,test = get_CELEB_A(args)\r\n",
        "   \r\n",
        "    bigan = TrainerBiGAN(args, train, device)\r\n",
        "    bigan.train()\r\n",
        "\r\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  0%|          | 1/391 [00:00<01:06,  5.85it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  1%|          | 2/391 [00:00<01:04,  5.99it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  1%|          | 3/391 [00:00<01:00,  6.40it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  1%|          | 4/391 [00:00<00:57,  6.75it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  1%|â         | 5/391 [00:00<00:54,  7.03it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  2%|â         | 6/391 [00:00<00:53,  7.21it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  2%|â         | 7/391 [00:00<00:52,  7.31it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  2%|â         | 8/391 [00:01<00:51,  7.42it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  2%|â         | 9/391 [00:01<00:50,  7.51it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  3%|â         | 10/391 [00:01<00:50,  7.56it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  3%|â         | 11/391 [00:01<00:50,  7.49it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  3%|â         | 12/391 [00:01<00:49,  7.61it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  3%|â         | 13/391 [00:01<00:49,  7.65it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  4%|â         | 14/391 [00:01<00:49,  7.68it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  4%|â         | 15/391 [00:02<00:48,  7.69it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  4%|â         | 16/391 [00:02<00:48,  7.69it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  4%|â         | 17/391 [00:02<00:48,  7.69it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  5%|â         | 18/391 [00:02<00:48,  7.68it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  5%|â         | 19/391 [00:02<00:48,  7.72it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  5%|â         | 20/391 [00:02<00:48,  7.71it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  5%|â         | 21/391 [00:02<00:48,  7.70it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  6%|â         | 22/391 [00:02<00:48,  7.68it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  6%|â         | 23/391 [00:03<00:47,  7.67it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  6%|â         | 24/391 [00:03<00:47,  7.70it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  6%|â         | 25/391 [00:03<00:47,  7.66it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  7%|â         | 26/391 [00:03<00:47,  7.65it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  7%|â         | 27/391 [00:03<00:47,  7.65it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  7%|â         | 28/391 [00:03<00:47,  7.64it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  7%|â         | 29/391 [00:03<00:47,  7.60it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  8%|â         | 30/391 [00:03<00:47,  7.58it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  8%|â         | 31/391 [00:04<00:47,  7.64it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  8%|â         | 32/391 [00:04<00:47,  7.62it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-1f7f7073feb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbigan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerBiGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mbigan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-c5573b62de97>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mge_loss_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0md_loss_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# # Defining labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;31m# y_true = Variable(torch.ones((x.size(0), 1)).to(self.device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m                     \u001b[0;31m# If no `miniters` was specified, adjust automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mmoveto\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0;31m# TODO: private method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_term_move_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAb8qyFM5SlF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7d86c961-bbb8-4beb-d690-ac6690c74fb8"
      },
      "source": [
        "from google.colab import files\r\n",
        "import shutil\r\n",
        "\r\n",
        "shutil.make_archive('/prj_gen_images', 'zip', '/prj_gen_images')\r\n",
        "files.download('/prj_gen_images.zip') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4d38bf89-2865-4cb6-8b89-3028dda213f7\", \"prj_gen_images.zip\", 691769)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwaGYQtNIFjg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "199f407b-071a-4ff0-8e29-65cdbcac4670"
      },
      "source": [
        "model_D = 'D.pt'\r\n",
        "model_G = 'G.pt'\r\n",
        "model_E = 'E.pt'\r\n",
        "\r\n",
        "G,D,E = bigan.getModel()\r\n",
        "\r\n",
        "if not os.path.exists(\"/prj_models\"):\r\n",
        "    os.makedirs(\"/prj_models\")\r\n",
        "\r\n",
        "path = F\"/prj_models/{model_D}\" \r\n",
        "torch.save(D.state_dict(), path)\r\n",
        "path = F\"/prj_models/{model_G}\" \r\n",
        "torch.save(G.state_dict(), path)\r\n",
        "path = F\"/prj_models/{model_E}\" \r\n",
        "torch.save(E.state_dict(), path)\r\n",
        "\r\n",
        "shutil.make_archive('/prj_models', 'zip', '/prj_models')\r\n",
        "files.download('/prj_models.zip') \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c8db0c35-3d65-4c7b-80eb-6705a2e789ff\", \"prj_models.zip\", 38413115)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RadBG7vmaPIc"
      },
      "source": [
        "#1-NEAREST NEIGHBOUR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "ydjhlwAHaVK-",
        "outputId": "2f356c1e-145a-460f-f5fe-50be9648fb09"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "\r\n",
        "vedere perche non va\r\n",
        "\r\n",
        "print(DATASET)\r\n",
        "\r\n",
        "if DATASET == \"SVHN\":\r\n",
        "  print(\"SVHN\")\r\n",
        "  X_train, y_train = train.dataset.data, train.dataset.labels\r\n",
        "  X_test, y_test = test.dataset.data, test.dataset.labels\r\n",
        "elif DATASET == \"cifar10\":\r\n",
        "  print(\"cifar10\")\r\n",
        "  X_train, y_train = train.dataset.data, train.dataset.targets\r\n",
        "  X_test, y_test = test.dataset.data, test.dataset.targets\r\n",
        "\r\n",
        "E.eval()\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    # EX_train = bigan.E(torch.tensor(X_train).float().to(bigan.device))\r\n",
        "    EX_train = bigan.E(torch.tensor(X_train).float())\r\n",
        "    EX_test = bigan.E(X_test)\r\n",
        "\r\n",
        "KNN = KNeighborsClassifier(n_neighbors=1)\r\n",
        "KNN.fit(EX_train, y_train)\r\n",
        "predictions = KNN.predict(EX_test)\r\n",
        "accuracy = np.sum(predictions == y_test) / len(y_test)\r\n",
        "print('Accuracy {:.2f}%'.format(accuracy*100))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar10\n",
            "cifar10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-12524b8678a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# EX_train = bigan.E(torch.tensor(X_train).float().to(bigan.device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mEX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mEX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-517f0504acfe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 3, 5, 5], expected input[50000, 32, 32, 3] to have 3 channels, but got 32 channels instead"
          ]
        }
      ]
    }
  ]
}